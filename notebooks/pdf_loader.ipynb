{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the PDF files from a directory into document structure\n",
    "##### Two approaches: 1) Manually iterate through files 2) Use DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs(directory_path):\n",
    "\n",
    "    pdf_documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            loader = PyMuPDFLoader(file_path)\n",
    "            docs = loader.load()\n",
    "            for each_doc in docs:\n",
    "                each_doc.metadata['file_type'] = 'pdf'\n",
    "            pdf_documents.extend(docs)\n",
    "    \n",
    "    return pdf_documents\n",
    "\n",
    "def process_all_pdfs_directory_loader(directory_path):\n",
    "\n",
    "    pdf_directory_loader = DirectoryLoader(\n",
    "        directory_path,\n",
    "        glob=\"**/*.pdf\",\n",
    "        loader_cls=PyMuPDFLoader\n",
    "    )\n",
    "    pdf_documents = pdf_directory_loader.load()\n",
    "\n",
    "    for doc in pdf_documents:\n",
    "        doc.metadata['file_type'] = 'pdf'\n",
    "\n",
    "    return pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all PDFs in the specified directory in a iterative manner\n",
    "# all_pdf_documents = process_all_pdfs(\"../data/pdf_files/\")\n",
    "# Process all PDFs in the specified directory using DirectoryLoader\n",
    "all_pdf_documents = process_all_pdfs_directory_loader(\"../data/pdf_files/\")\n",
    "print(all_pdf_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Splitter to perform chunking on the loaded documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters  import RecursiveCharacterTextSplitter\n",
    "\n",
    "def text_splitter(documents, chunk_size=1000, chunk_overlap=200):\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Total document loaders: {len(documents)} and Number of chunks after splitting: {len(split_docs)}\")\n",
    "\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter_documents = text_splitter(all_pdf_documents)\n",
    "print(text_splitter_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and VectorDB Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import chromadb\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-miniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimensions: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x27895f64980>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"\n",
    "    Creates embeddings for given documents using sentence_transformer with a specified embedding model.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_model_name=\"all-miniLM-L6-v2\"):\n",
    "        self.embedding_model_name = embedding_model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Loads the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.embedding_model_name}\")\n",
    "            self.model = SentenceTransformer(self.embedding_model_name)\n",
    "            print(\"Model loaded successfully. Embedding dimensions:\", self.model.get_sentence_embedding_dimension())\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, page_content_text):\n",
    "\n",
    "        print(f\"Generating embeddings for {len(page_content_text)} documents...\")\n",
    "        embeddings = self.model.encode(page_content_text, show_progress_bar=True)\n",
    "        print(f\"Embeddings generated successfully with shape {embeddings.shape}\")\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector storage initialized at: ../data/vector_storage\n",
      "Existing documents in the collection name pdf_documents is 33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStoreManager at 0x278957497f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStoreManager:\n",
    "    \"\"\"\n",
    "    Manages the creation and storage of vector embeddings using FAISS.\n",
    "    \"\"\"\n",
    "    def __init__(self, collection_name=\"pdf_documents\", persist_directory=\"../data/vector_storage\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.db_client = None\n",
    "        self._initialize_storage()\n",
    "\n",
    "    def _initialize_storage(self):\n",
    "        try:\n",
    "            # Create a persistent directory for vector storage\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            # Initialize ChromaDB client\n",
    "            self.db_client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            # Create or get the collection\n",
    "            self.collection = self.db_client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"Collection of PDF document embeddings for RAG application\"}\n",
    "            )\n",
    "            print(f\"Vector storage initialized at: {self.persist_directory}\")\n",
    "            print(f\"Existing documents in the collection name {self.collection_name} is {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing storage directory: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents_to_collection(self, documents, embeddings):\n",
    "        \"\"\"Adds documents and their embeddings to the vector store collection.\"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"The number of documents must match the number of embeddings.\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to the vector store collection...\")\n",
    "\n",
    "        # Prepare data for insertion to the vector store collection\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for index, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{index}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            metadata = dict(doc.metadata)  # Copy existing metadata\n",
    "            metadata['doc_index'] = index\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            documents_text.append(doc.page_content)\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text,\n",
    "                embeddings=embeddings_list\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to the vector store collection {self.collection_name}.\")\n",
    "            print(f\"Total documents in the collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "vector_store_manager = VectorStoreManager()\n",
    "vector_store_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for the split documents\n",
    "page_content_text = [doc.page_content for doc in text_splitter_documents]\n",
    "embeddings_data = embedding_manager.generate_embeddings(page_content_text)\n",
    "\n",
    "# Store the embeddings to vector store\n",
    "vector_store_manager.add_documents_to_collection(\n",
    "    documents=text_splitter_documents,\n",
    "    embeddings=embeddings_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever Pipeline from Vector Storage DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 1 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully with shape (1, 384)\n",
      "Top 5 retrieved documents for the query 'Concerns about AI':\n",
      "Retrieved 5 results after applying score threshold of 0.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_17ddeb75_11',\n",
       "  'content': 'Intelligence is also viewed as a great tool for better cybersecurity. Many banks are\\nusing AI as a means to identify unauthorized credit cards uses. From analyzing\\ncomplex genetic data to perform the most delicate surgeries at the highest precision\\nis also being worked on to integrate with AI. We all know about companies like\\nTesla and Apple working to make flawless self-driving cars which is going to have\\ngame changing impacts on the future of transportation.\\nConcerns about AI\\nOne of the most immediate concerns about Artificial Intelligence is the fear of\\nlosing jobs. Artificial Intelligence enhancing automation is also causing huge job\\nlosses around the world. According to a Forbes article, it is predicted that by 2025\\nautomation will cause a loss of 85 million jobs. [6] Bigger fears regarding AI\\nincludes the scenario whereas machines become smarter and smarter they going to\\nend up being as opinionated and biased like some of the people training it.',\n",
       "  'metadata': {'file_path': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf',\n",
       "   'subject': 'Article about artificial intelligence (AI) written by Ryerson Computer Science student, Dibbyo Saha, for Science Rendezvous.',\n",
       "   'trapped': '',\n",
       "   'creationDate': \"D:20210505130455+01'00'\",\n",
       "   'author': '',\n",
       "   'doc_index': 11,\n",
       "   'producer': 'Skia/PDF m92 Google Docs Renderer',\n",
       "   'file_type': 'pdf',\n",
       "   'page': 5,\n",
       "   'moddate': '2021-05-05T13:04:55+01:00',\n",
       "   'format': 'PDF 1.4',\n",
       "   'creationdate': '2021-05-05T13:04:55+01:00',\n",
       "   'keywords': '',\n",
       "   'modDate': \"D:20210505130455+01'00'\",\n",
       "   'creator': '',\n",
       "   'source': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf',\n",
       "   'content_length': 965,\n",
       "   'total_pages': 9,\n",
       "   'title': 'A Brief Introduction to Artificial Intelligence'},\n",
       "  'similarity_score': 0.2813958525657654,\n",
       "  'distance': 0.7186041474342346,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_d1e424b8_14',\n",
       "  'content': 'great tool in the future of education. AI can be used to analyze data from an\\nindividual’s personal and intellectual needs, capabilities, choices and limitations to\\ndevelop customized curriculum, strategies and schedules that will be more well\\nsuited, appealling and inclusive of most, if not all, children and adults. The uses of\\nAI are also going to change the way we are going to commute in the future. In\\naddition to self-driving cars, work is being done to manufacture “self-flying”\\nplanes and drones that conveniently deliver your food faster and better. One of the\\nbiggest concerns about AI is that jobs are being replaced due to automation.\\nHowever, AI might be creating more jobs than it replaces. This will change the\\nway humans work by creating new types of jobs.\\nSource: https://hackernoon.com/artificial-intelligence-and-big-data-zys3258\\nAI is still in a fairly preliminary (but rapidly growing) stage today and it requires',\n",
       "  'metadata': {'moddate': '2021-05-05T13:04:55+01:00',\n",
       "   'page': 6,\n",
       "   'title': 'A Brief Introduction to Artificial Intelligence',\n",
       "   'creator': '',\n",
       "   'trapped': '',\n",
       "   'modDate': \"D:20210505130455+01'00'\",\n",
       "   'total_pages': 9,\n",
       "   'creationdate': '2021-05-05T13:04:55+01:00',\n",
       "   'source': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf',\n",
       "   'file_path': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf',\n",
       "   'producer': 'Skia/PDF m92 Google Docs Renderer',\n",
       "   'creationDate': \"D:20210505130455+01'00'\",\n",
       "   'subject': 'Article about artificial intelligence (AI) written by Ryerson Computer Science student, Dibbyo Saha, for Science Rendezvous.',\n",
       "   'content_length': 936,\n",
       "   'doc_index': 14,\n",
       "   'format': 'PDF 1.4',\n",
       "   'keywords': '',\n",
       "   'author': '',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.2568659782409668,\n",
       "  'distance': 0.7431340217590332,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_8533e18c_12',\n",
       "  'content': 'includes the scenario whereas machines become smarter and smarter they going to\\nend up being as opinionated and biased like some of the people training it.\\nAutomatization of weapons is also a big reason people worry about the future of\\nArtificial Intelligence. The idea that weapons can be used to search and target\\nsomeone with pre-programmed instructions and the misuse of this by governments\\nor mafias or rogue AI can be something very deadly and devastating. However,\\nthere are many myths in disguise of concerns surrounding AI that spreads panic\\nand misinformation. AI today is nowhere near to become a super-intelligent entity\\nand turn into our overlords like in sci-fi movies. However, heavy regulations and\\ncautions are being advised by Big Tech giants like Elon Musk while developing\\nthis industry.\\nArtificial Intelligence and The Future\\nIt is said that AI is the greatest thing humankind has ever worked on. AI is being',\n",
       "  'metadata': {'modDate': \"D:20210505130455+01'00'\",\n",
       "   'format': 'PDF 1.4',\n",
       "   'subject': 'Article about artificial intelligence (AI) written by Ryerson Computer Science student, Dibbyo Saha, for Science Rendezvous.',\n",
       "   'doc_index': 12,\n",
       "   'author': '',\n",
       "   'keywords': '',\n",
       "   'creator': '',\n",
       "   'moddate': '2021-05-05T13:04:55+01:00',\n",
       "   'creationdate': '2021-05-05T13:04:55+01:00',\n",
       "   'page': 5,\n",
       "   'file_type': 'pdf',\n",
       "   'title': 'A Brief Introduction to Artificial Intelligence',\n",
       "   'source': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf',\n",
       "   'creationDate': \"D:20210505130455+01'00'\",\n",
       "   'producer': 'Skia/PDF m92 Google Docs Renderer',\n",
       "   'total_pages': 9,\n",
       "   'file_path': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf',\n",
       "   'content_length': 929,\n",
       "   'trapped': ''},\n",
       "  'similarity_score': 0.2224637269973755,\n",
       "  'distance': 0.7775362730026245,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_9dcac137_13',\n",
       "  'content': 'this industry.\\nArtificial Intelligence and The Future\\nIt is said that AI is the greatest thing humankind has ever worked on. AI is being\\nused in image and speech recognition and analysis which will be far better than\\nhuman recognition of image and speech and its application stretches wide and far.\\nThere are research and works being conducted using AI that is going to play a very\\nimportant role in our future healthcare. AI is being worked on to cure Alzheimer’s\\ndisease and someday even blindness. Someone with dyslexia is being helped to\\nread better with the help of AI. Genetic data is being analyzed by bioinformatics;\\ndata science integrated with AI for way better data analysis in healthcare that has\\nnot been possible for us in the past. Fields like cancer research and other such\\ndiseases are being impacted greatly by advanced applications of AI. AI can be a',\n",
       "  'metadata': {'keywords': '',\n",
       "   'subject': 'Article about artificial intelligence (AI) written by Ryerson Computer Science student, Dibbyo Saha, for Science Rendezvous.',\n",
       "   'page': 5,\n",
       "   'producer': 'Skia/PDF m92 Google Docs Renderer',\n",
       "   'creator': '',\n",
       "   'title': 'A Brief Introduction to Artificial Intelligence',\n",
       "   'doc_index': 13,\n",
       "   'source': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'creationDate': \"D:20210505130455+01'00'\",\n",
       "   'total_pages': 9,\n",
       "   'modDate': \"D:20210505130455+01'00'\",\n",
       "   'author': '',\n",
       "   'trapped': '',\n",
       "   'creationdate': '2021-05-05T13:04:55+01:00',\n",
       "   'file_path': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf',\n",
       "   'moddate': '2021-05-05T13:04:55+01:00',\n",
       "   'content_length': 869,\n",
       "   'format': 'PDF 1.4'},\n",
       "  'similarity_score': 0.16074562072753906,\n",
       "  'distance': 0.8392543792724609,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_8da3876a_0',\n",
       "  'content': 'A Brief Introduction to Artificial Intelligence\\nWhat is AI and how is it going to shape the future\\nBy Dibbyo Saha, Undergraduate Student, Computer Science, Ryerson University\\nWhat is Artificial Intelligence?\\nImage by\\xa0Gerd Altmann\\xa0from\\xa0Pixabay\\nGenerally speaking, Artificial Intelligence is a computing concept that helps a\\nmachine think and solve complex problems as we humans do with our intelligence.\\nFor example, we perform a task, make mistakes and learn from our mistakes (At\\nleast the wise ones of us do!). Likewise, an AI or Artificial Intelligence is supposed\\nto work on a problem, make some mistakes in solving the problem and learn from\\nthe problems in a self-correcting manner as a part of its self-improvement. Or in\\nother words, think of this like playing a game of chess. Every bad move you make\\nreduces your chances of winning the game. So, every time you lose against your\\nfriend, you try remembering the moves you made which you shouldn’t have and',\n",
       "  'metadata': {'page': 0,\n",
       "   'creationDate': \"D:20210505130455+01'00'\",\n",
       "   'moddate': '2021-05-05T13:04:55+01:00',\n",
       "   'title': 'A Brief Introduction to Artificial Intelligence',\n",
       "   'content_length': 964,\n",
       "   'trapped': '',\n",
       "   'author': '',\n",
       "   'file_type': 'pdf',\n",
       "   'creator': '',\n",
       "   'keywords': '',\n",
       "   'subject': 'Article about artificial intelligence (AI) written by Ryerson Computer Science student, Dibbyo Saha, for Science Rendezvous.',\n",
       "   'modDate': \"D:20210505130455+01'00'\",\n",
       "   'creationdate': '2021-05-05T13:04:55+01:00',\n",
       "   'producer': 'Skia/PDF m92 Google Docs Renderer',\n",
       "   'doc_index': 0,\n",
       "   'file_path': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf',\n",
       "   'total_pages': 9,\n",
       "   'format': 'PDF 1.4',\n",
       "   'source': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf'},\n",
       "  'similarity_score': 0.15855026245117188,\n",
       "  'distance': 0.8414497375488281,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"\n",
    "    Handles query based retrieval frpm the vector store for RAG applications.\n",
    "    \"\"\"\n",
    "    def __init__(self, vector_store_manager, embedding_manager):\n",
    "        self.vector_store_manager = vector_store_manager\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query, top_k=5, score_threshold=0.0):\n",
    "\n",
    "        # Generate the embedding for the query\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in Vector storage with the query embedding\n",
    "        vector_results = self.vector_store_manager.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=top_k\n",
    "        )\n",
    "\n",
    "        # Process the vector result\n",
    "        processed_results = []\n",
    "\n",
    "        if vector_results['documents'] and vector_results['documents'][0]:\n",
    "            print(f\"Top {top_k} retrieved documents for the query '{query}':\")\n",
    "            documents = vector_results['documents'][0]\n",
    "            metadatas = vector_results['metadatas'][0]\n",
    "            distances = vector_results['distances'][0]\n",
    "            ids = vector_results['ids'][0]\n",
    "\n",
    "            for index, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                # Convert distance to similarity score (ChromaDB uses cosine distance, lower is better)\n",
    "                similarity_score = 1 - distance\n",
    "\n",
    "                if similarity_score >= score_threshold:\n",
    "                    processed_results.append({\n",
    "                        'id': doc_id,\n",
    "                        'content': document,\n",
    "                        'metadata': metadata,\n",
    "                        'similarity_score': similarity_score,\n",
    "                        'distance': distance,\n",
    "                        'rank': index + 1\n",
    "                    })\n",
    "            print(f\"Retrieved {len(processed_results)} results after applying score threshold of {score_threshold}.\")\n",
    "        else:\n",
    "            print(f\"No documents retrieved for the query '{query}'.\")\n",
    "\n",
    "        return processed_results\n",
    "    \n",
    "rag_retriever = RAGRetriever(vector_store_manager, embedding_manager)\n",
    "query = \"Concerns about AI\"\n",
    "retrieved_results = rag_retriever.retrieve(query)\n",
    "retrieved_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration VectorDB Context pipeline with LLM output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RAG pipeline with Groq LLM\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(api_key=groq_api_key, model=\"openai/gpt-oss-20b\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "def simple_rag(query, retriever, llm, top_k=5):\n",
    "\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retriever.retrieve(query, top_k=top_k)\n",
    "\n",
    "    # Prepare context for the LLM\n",
    "    # context = \"\\n\\n\".join([f\"Document {doc['rank']} (Score: {doc['similarity_score']:.4f}):\\n{doc['content']}\" for doc in retrieved_docs])\n",
    "    context = \"\\n\\n\".join([f\"{doc['content']}\" for doc in retrieved_docs]) if retrieved_docs else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant documents found to answer the query.\" \n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = f\"Using the following context, answer the question in pointer wise:\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "\n",
    "    # Get response from LLM\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 1 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully with shape (1, 384)\n",
      "Top 5 retrieved documents for the query 'What are the key concerns about AI mentioned in the documents?':\n",
      "Retrieved 5 results after applying score threshold of 0.0.\n",
      "content='**Key concerns about AI highlighted in the documents**\\n\\n- **Job displacement**  \\n  - Automation is projected to eliminate up to 85\\u202fmillion jobs by 2025.  \\n  - Fear that AI will replace human workers across many sectors.\\n\\n- **Bias and opinion‑laden decision‑making**  \\n  - AI systems can inherit and amplify the biases present in their training data.  \\n  - Machines may become “opinionated” and unfair, mirroring the prejudices of their creators.\\n\\n- **Weaponization and misuse**  \\n  - Autonomous weapons could target individuals based on pre‑programmed instructions.  \\n  - Potential for governments, criminal groups, or rogue AI to deploy lethal autonomous systems.\\n\\n- **Myths and misinformation**  \\n  - Over‑exaggerated fears of AI becoming a super‑intelligent overlord (as in sci‑fi).  \\n  - Public panic often stems from misunderstandings about current AI capabilities.\\n\\n- **Regulatory and ethical oversight**  \\n  - Calls for stringent regulations and caution from industry leaders (e.g., Elon Musk).  \\n  - Need for frameworks to ensure safe, responsible AI development and deployment.\\n\\n- **Privacy and security risks**  \\n  - AI’s ability to analyze sensitive data (e.g., credit card usage, genetic information) raises concerns about misuse and data breaches.\\n\\nThese points capture the main apprehensions expressed across the provided texts.' additional_kwargs={'reasoning_content': 'We need to answer in pointer wise. The question: \"What are the key concerns about AI mentioned in the documents?\" We need to list key concerns. From context: job loss due to automation, bias/opinionated AI, weaponization, myths/misinfo, fear of superintelligence, heavy regulations needed, etc. Also concerns about AI replacing jobs, but also creating new jobs. But key concerns: job loss, bias, weaponization, superintelligence myth, need for regulation. Also concerns about AI being opinionated and biased like training data. Also concerns about misuse by governments or mafias. Also concerns about AI being used for unauthorized credit card uses? That is more use case. So answer pointer wise. Let\\'s produce bullet points.'} response_metadata={'token_usage': {'completion_tokens': 443, 'prompt_tokens': 1056, 'total_tokens': 1499, 'completion_time': 0.440109688, 'completion_tokens_details': {'reasoning_tokens': 152}, 'prompt_time': 0.056062013, 'prompt_tokens_details': None, 'queue_time': 0.048535786, 'total_time': 0.496171701}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--a55b06b0-9962-45bf-b16d-c35c7742bfcb-0' usage_metadata={'input_tokens': 1056, 'output_tokens': 443, 'total_tokens': 1499}\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the key concerns about AI mentioned in the documents?\"\n",
    "rag_response = simple_rag(query, rag_retriever, llm, top_k=5)\n",
    "print(rag_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 1 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated successfully with shape (1, 384)\n",
      "Top 5 retrieved documents for the query 'What are the key concerns about AI mentioned in the documents?':\n",
      "Retrieved 1 results after applying score threshold of 0.2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Key concerns about AI mentioned are:  \n",
      "1. **Job displacement** – automation could eliminate millions of jobs (e.g., 85 million by 2025).  \n",
      "2. **Bias and opinionation** – as AI systems learn from human data, they risk becoming biased or opinionated in ways that mirror their trainers.\n",
      "Sources: [{'source': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf', 'page': 5, 'similarity_score': 0.20004886388778687, 'metadata': {'trapped': '', 'file_type': 'pdf', 'doc_index': 11, 'keywords': '', 'creationDate': \"D:20210505130455+01'00'\", 'source': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf', 'total_pages': 9, 'file_path': '..\\\\data\\\\pdf_files\\\\A_Brief_Introduction_To_AI.pdf', 'format': 'PDF 1.4', 'creator': '', 'creationdate': '2021-05-05T13:04:55+01:00', 'producer': 'Skia/PDF m92 Google Docs Renderer', 'title': 'A Brief Introduction to Artificial Intelligence', 'page': 5, 'modDate': \"D:20210505130455+01'00'\", 'author': '', 'moddate': '2021-05-05T13:04:55+01:00', 'content_length': 965, 'subject': 'Article about artificial intelligence (AI) written by Ryerson Computer Science student, Dibbyo Saha, for Science Rendezvous.'}}]\n",
      "Confidence Score: 0.20004886388778687\n"
     ]
    }
   ],
   "source": [
    "def rag_advanced(query, retriever, llm, top_k=5, score_threshold=0.2, return_context=True):\n",
    "    \"\"\"\n",
    "    RAG Pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retriever.retrieve(query, top_k=top_k, score_threshold=score_threshold)\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        return \"No relevant documents found to answer the query.\"\n",
    "\n",
    "    # Prepare context for the LLM\n",
    "    context = \"\\n\\n\".join([f\"{doc['content']}\" for doc in retrieved_docs]) if retrieved_docs else \"\"\n",
    "\n",
    "    sources = [\n",
    "        {\n",
    "            'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "            'page': doc['metadata'].get('page', 'unknown'),\n",
    "            'similarity_score': doc['similarity_score']\n",
    "        }\n",
    "        for doc in retrieved_docs\n",
    "    ]\n",
    "    confidence_scores = max([doc['similarity_score'] for doc in retrieved_docs])\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "\n",
    "    # Get response from LLM\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence_score': confidence_scores\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "\n",
    "    return output\n",
    "\n",
    "query = \"What are the key concerns about AI mentioned in the documents?\"\n",
    "result = rag_advanced(query, rag_retriever, llm, top_k=5, score_threshold=0.2, return_context=True)\n",
    "print('Answer:', result['answer'])\n",
    "print('Sources:', result['sources'])\n",
    "print('Confidence Score:', result['confidence_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG Demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
